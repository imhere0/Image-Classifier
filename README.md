At first one convulated layer: ```models.add(tf.keras.layers.Conv2D(32, (3, 3), padding = "valid", activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))``` was added followed by 2 by 2 max pooling layer and a dropout layer of 0.4 rate. A hidden layer of 128 units was added that was followed by drop out layer of 0.4 rate along with the output layer after flatening the convulated layer. **This produced overall accuracy of 0.4582 and loss of 24.7376**.  Then  I added another convulated layer this time with 64 filters foll0wed by drop out layer of 0.2 rate. **This produced a loss of 0.6484 and loss of 0.7119.**  
**Finally I made the convulation network of 3 convulated layers with 32, 64 and 128 filters each followed with 2 by 2 max-pooling layer**. The drop out layer that was added previously had a bit too much drop out frequency hence new  drop out layers was added to each convulated layer with 20% drop out to avoid overfitting. **At last a hidden layer followed these convulated layer with 128 units. Subsequently a drop out layer with 0.2 frequency rate was added to the hidden layer**.